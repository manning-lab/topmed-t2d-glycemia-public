{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Hail with Firecloud data\n",
    "\n",
    "### Here we'll go through how we can access a Firecloud workspace, manipulate the data model and explore some aspects of the workspace data in Hail.\n",
    "\n",
    "### First, load some useful tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install firecloud\n",
    "from firecloud import fiss\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_row', 10000)\n",
    "import io\n",
    "import numpy as np\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, see what kind of permissions we have on the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insufficient permissions to perform operation on topmed-shared/topmed-shared\n"
     ]
    }
   ],
   "source": [
    "control = fiss.fapi.get_workspace_acl(\"topmed-shared\", \"topmed-shared\").json()#['acl']\n",
    "print control['message']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we are not an owner, we'll get denied when trying to see who else is part of the workspace. But, since we are a writer, this does not stop us from working with the data. \n",
    "\n",
    "### We can look at how many samples are participants we have within the Firecloud data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ent_types = fiss.fapi.list_entity_types(\"topmed-shared\", \"topmed-shared\").json()\n",
    "for t in ent_types.keys():\n",
    "    print t, \"count:\", ent_types[t]['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = fiss.fapi.get_entities(\"topmed-shared\",\"topmed-shared\", \"sample\").json()\n",
    "sample_tups = [(samples[i]['attributes']['participant']['entityName'],samples[i]['attributes']['study']) for i in xrange(0,len(samples))]\n",
    "pid_to_study = dict()\n",
    "for e in sample_tups:\n",
    "    pid_to_study.setdefault(e[1], []).append(e[0])\n",
    "\n",
    "    num_dict = {d:len(pid_to_study[d]) for d in pid_to_study}\n",
    "print 'Included studies(# participants):\\n', '\\n'.join([d+'('+str(num_dict[d])+')' for d in num_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Hail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## start hail context\n",
    "from hail import *\n",
    "hc = HailContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The path to the genotype file is also in the Firecloud data model. Next we'll parse this information out and load the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_sets = fiss.fapi.get_entities('topmed-shared','topmed-shared', 'sample_set').json()\n",
    "print 'Sample set name:', samples_sets[0]['name']\n",
    "print 'Sample set fields:', ', '.join(samples_sets[0]['attributes'].keys())\n",
    "vcf_files = samples_sets[0]['attributes']['vcf']['items']\n",
    "print '# of vcf files:', len(vcf_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We may want to actually add the data contained in the data model to the genotype file as an annotation. This can be done with Hail but requires some manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>FAMID</th>\n",
       "      <th>sex</th>\n",
       "      <th>T2D</th>\n",
       "      <th>T2D_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000-10D</td>\n",
       "      <td>1000-10D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>1001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>63.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001-10D</td>\n",
       "      <td>1001-10D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002-10D</td>\n",
       "      <td>1002-10D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant     FAMID  sex  T2D  T2D_AGE\n",
       "0         100       100    1    1    70.99\n",
       "1    1000-10D  1000-10D    1    1    54.00\n",
       "2        1001      1001    2    0    63.80\n",
       "3    1001-10D  1001-10D    1    1    55.00\n",
       "4    1002-10D  1002-10D    1    1    60.00"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model = fiss.fapi.get_entities_tsv(\"topmed-shared\",\"topmed-shared\", \"sample\")\n",
    "data_model_text = pd.read_csv(io.StringIO(data_model.text), sep='\\t')[['entity:sample_id','participant','CENTER','study','topmed_project']]\n",
    "data_model_text.rename(columns = {'entity:sample_id':'ent_sample_id', 'participant':'sample_id'}, inplace = True)\n",
    "data_model_text[['study', 'topmed_project']] = data_model_text[['study', 'topmed_project']].astype(str)\n",
    "data_model_text.info()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlctx = SQLContext(hc.sc)\n",
    "spark_df = sqlctx.createDataFrame(data_model_text)\n",
    "kt = KeyTable.from_dataframe(spark_df,key='sample_id') \n",
    "vds = vds.annotate_samples_table(kt, root='sa')\n",
    "\n",
    "data_model_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the sample scheme of our data to see what we have added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struct{\n",
      "     FAMID: String,\n",
      "     sex: Long,\n",
      "     T2D: Long,\n",
      "     T2D_AGE: Double\n",
      " }\n"
     ]
    }
   ],
   "source": [
    "pprint(vds.sample_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same counting samples per cohort as above with Hail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0L: 1408L, 1L: 1466L}\n"
     ]
    }
   ],
   "source": [
    "pprint(vds.query_samples('samples.map(s => sa.topmed_project).counter()'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For another level of annotation, we can run the built in QC from Hail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds = vds.variant_qc().cache().sample_qc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the sample and variant scheme to see what we have added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struct{\n",
      "     FAMID: String,\n",
      "     sex: Long,\n",
      "     T2D: Long,\n",
      "     T2D_AGE: Double,\n",
      "     qc: Struct{\n",
      "         callRate: Double,\n",
      "         nCalled: Int,\n",
      "         nNotCalled: Int,\n",
      "         nHomRef: Int,\n",
      "         nHet: Int,\n",
      "         nHomVar: Int,\n",
      "         nSNP: Int,\n",
      "         nInsertion: Int,\n",
      "         nDeletion: Int,\n",
      "         nSingleton: Int,\n",
      "         nTransition: Int,\n",
      "         nTransversion: Int,\n",
      "         dpMean: Double,\n",
      "         dpStDev: Double,\n",
      "         gqMean: Double,\n",
      "         gqStDev: Double,\n",
      "         nNonRef: Int,\n",
      "         rTiTv: Double,\n",
      "         rHetHomVar: Double,\n",
      "         rInsertionDeletion: Double\n",
      "     }\n",
      " }\n"
     ]
    }
   ],
   "source": [
    "pprint(vds.sample_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struct{\n",
      "     rsid: String,\n",
      "     qual: Double,\n",
      "     filters: Set[String],\n",
      "     info: Struct{\n",
      "         AC: Array[Int],\n",
      "         AN: Int,\n",
      "         SOURCE: Array[String],\n",
      "         VT: Array[String],\n",
      "         LDAF: Double,\n",
      "         AVGPOST: Double,\n",
      "         RSQ: Double,\n",
      "         ERATE: Double,\n",
      "         THETA: Double,\n",
      "         CIEND: Array[Int],\n",
      "         CIPOS: Array[Int],\n",
      "         END: Int\n",
      "     },\n",
      "     qc: Struct{\n",
      "         callRate: Double,\n",
      "         AC: Int,\n",
      "         AF: Double,\n",
      "         nCalled: Int,\n",
      "         nNotCalled: Int,\n",
      "         nHomRef: Int,\n",
      "         nHet: Int,\n",
      "         nHomVar: Int,\n",
      "         dpMean: Double,\n",
      "         dpStDev: Double,\n",
      "         gqMean: Double,\n",
      "         gqStDev: Double,\n",
      "         nNonRef: Int,\n",
      "         rHeterozygosity: Double,\n",
      "         rHetHomVar: Double,\n",
      "         rExpectedHetFrequency: Double,\n",
      "         pHWE: Double\n",
      "     }\n",
      " }\n"
     ]
    }
   ],
   "source": [
    "pprint(vds.variant_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also use Hail to further annotate and get some useful statistics, per cohort, from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pop</th>\n",
       "      <th>Singletons</th>\n",
       "      <th>Doubletons</th>\n",
       "      <th>Tripletons_to_01</th>\n",
       "      <th>Zero_1_to_1</th>\n",
       "      <th>One_to_10</th>\n",
       "      <th>Ten_above</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>220921.0</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>88768.0</td>\n",
       "      <td>2458273.0</td>\n",
       "      <td>20264868.0</td>\n",
       "      <td>113899937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>183990.0</td>\n",
       "      <td>107430.0</td>\n",
       "      <td>82624.0</td>\n",
       "      <td>2345580.0</td>\n",
       "      <td>19400797.0</td>\n",
       "      <td>109295707.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pop  Singletons  Doubletons  Tripletons_to_01  Zero_1_to_1   One_to_10  \\\n",
       "0    1    220921.0    121000.0           88768.0    2458273.0  20264868.0   \n",
       "1    0    183990.0    107430.0           82624.0    2345580.0  19400797.0   \n",
       "\n",
       "     Ten_above  \n",
       "0  113899937.0  \n",
       "1  109295707.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## actually want to look at proportion per cohort of singletons/doubles/etc\n",
    "\n",
    "# annotate by allele count and frequency for each sample\n",
    "vds = vds.annotate_samples_expr('sa.nDoubles = gs.filter(g => g.isHet() && va.qc.AC == 2).count()')\n",
    "vds = vds.annotate_samples_expr('sa.nTri_to_one = gs.filter(g => g.isHet() && va.qc.AC == 3).count()')\n",
    "vds = vds.annotate_samples_expr('sa.nOne = gs.filter(g => g.isHet() && va.qc.AF < 0.01 && va.qc.AF > 0.001).count()')\n",
    "vds = vds.annotate_samples_expr('sa.nTen = gs.filter(g => g.isHet() && va.qc.AF < 0.1 && va.qc.AF > 0.01).count()')\n",
    "vds = vds.annotate_samples_expr('sa.nTen_above = gs.filter(g => g.isHet() && va.qc.AF > 0.1).count()')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(vds.samples_table()\n",
    " .aggregate_by_key(key_expr=['Pop = sa.topmed_project'], agg_expr=['Singletons = sa.map(s => sa.qc.nSingleton).stats().sum',\n",
    "                                                                                          'Doubletons = sa.map(s => sa.nDoubles).stats().sum',\n",
    "                                                                                          'Tripletons_to_01 = sa.map(sa => sa.nTri_to_one).stats().sum',\n",
    "                                                                                          'Zero_1_to_1 = sa.map(sa => sa.nOne).stats().sum',\n",
    "                                                                                          'One_to_10 = sa.map(sa => sa.nTen).stats().sum',\n",
    "                                                                                          'Ten_above = sa.map(sa => sa.nTen_above).stats().sum']).to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more statistics on our >10% frequency variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pop</th>\n",
       "      <th>Ten.mean</th>\n",
       "      <th>Ten.stdev</th>\n",
       "      <th>Ten.min</th>\n",
       "      <th>Ten.max</th>\n",
       "      <th>Ten.nNotMissing</th>\n",
       "      <th>Ten.sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>77694.363574</td>\n",
       "      <td>6482.860547</td>\n",
       "      <td>43951.0</td>\n",
       "      <td>96586.0</td>\n",
       "      <td>1466</td>\n",
       "      <td>113899937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>77624.791903</td>\n",
       "      <td>6225.905044</td>\n",
       "      <td>54558.0</td>\n",
       "      <td>95784.0</td>\n",
       "      <td>1408</td>\n",
       "      <td>109295707.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pop      Ten.mean    Ten.stdev  Ten.min  Ten.max  Ten.nNotMissing  \\\n",
       "0    1  77694.363574  6482.860547  43951.0  96586.0             1466   \n",
       "1    0  77624.791903  6225.905044  54558.0  95784.0             1408   \n",
       "\n",
       "       Ten.sum  \n",
       "0  113899937.0  \n",
       "1  109295707.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vds.samples_table().aggregate_by_key(key_expr=['Pop = sa.T2D'], agg_expr=['Ten = sa.map(s => sa.nTen_above).stats()']).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running PCA on the genotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do pca\n",
    "pca = vds.pca('sa.pca', k=5, eigenvalues='global.eigen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the differences in families within the studies by principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define some colors\n",
    "c = [\"aec7e8\",\"ff7f0e\",\"ffbb78\",\"2ca02c\",\"98df8a\",\"d62728\",\"ff9896\",\"9467bd\",\"c5b0d5\",\"8c564b\",\"c49c94\"]\n",
    "cz = zip(vds.query_samples('samples.map(s => sa.topmed_project).counter()').keys(),c)\n",
    "colors = {t[0]: t[1] for t in cz}\n",
    "# show the pca results\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import Counter\n",
    "from math import log, isnan\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "pca_table = pca.samples_table().to_pandas()\n",
    "plt.scatter(pca_table[\"sa.pca.PC1\"], pca_table[\"sa.pca.PC2\"],\n",
    "            c = pca_table[\"sa.metadata.SuperPopulation\"].map(colors),\n",
    "            alpha = .5)\n",
    "plt.xlim(-0.6, 0.6)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "legend_entries = [mpatches.Patch(color=c, label=pheno) for pheno, c in colors.items()]\n",
    "plt.legend(handles=legend_entries, loc=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}