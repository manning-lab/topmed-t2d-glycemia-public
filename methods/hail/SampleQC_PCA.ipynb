{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecloud import fiss\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_row', 10000)\n",
    "import io\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'acl']\n"
     ]
    }
   ],
   "source": [
    "control = fiss.fapi.get_workspace_acl(\"topmed-shared\", \"topmed-shared\").json()#['acl']\n",
    "print control.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 2.0.2\n",
      "SparkUI available at http://10.128.0.13:4041\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.1-6f85985\n"
     ]
    }
   ],
   "source": [
    "## start hail context\n",
    "from hail import *\n",
    "hc = HailContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample set name: freeze5b_minDP10\n",
      "Sample set fields: wgsa_subset, gds, vcf, bcf, tbi, cov_grm, samples, wgsa_raw, cor_grm\n",
      "# of vcf files: 23\n"
     ]
    }
   ],
   "source": [
    "samples_sets = fiss.fapi.get_entities('topmed-shared','topmed-shared', 'sample_set').json()\n",
    "print 'Sample set name:', samples_sets[0]['name']\n",
    "print 'Sample set fields:', ', '.join(samples_sets[0]['attributes'].keys())\n",
    "vcf_files = samples_sets[0]['attributes']['vcf']['items']\n",
    "print '# of vcf files:', len(vcf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = hc.read(\"gs://fc-adaae650-a458-4c56-8a55-d96fa463a5c6/vds_topmed/freeze.5b.chr10.pass_and_fail.gtonly.minDP10.vds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 56436 entries, 0 to 56435\n",
      "Data columns (total 5 columns):\n",
      "ent_sample_id     56436 non-null object\n",
      "sample_id         56436 non-null object\n",
      "CENTER            56436 non-null object\n",
      "study             56436 non-null object\n",
      "topmed_project    56436 non-null object\n",
      "dtypes: object(5)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_sample_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>CENTER</th>\n",
       "      <th>study</th>\n",
       "      <th>topmed_project</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> freeze5a_NWD100014</td>\n",
       "      <td> NWD100014</td>\n",
       "      <td>       uw</td>\n",
       "      <td>      JHS</td>\n",
       "      <td>      JHS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> freeze5a_NWD100018</td>\n",
       "      <td> NWD100018</td>\n",
       "      <td>    broad</td>\n",
       "      <td> COPDGene</td>\n",
       "      <td>     COPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> freeze5a_NWD100027</td>\n",
       "      <td> NWD100027</td>\n",
       "      <td> macrogen</td>\n",
       "      <td> GeneSTAR</td>\n",
       "      <td> GeneSTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> freeze5a_NWD100047</td>\n",
       "      <td> NWD100047</td>\n",
       "      <td>       uw</td>\n",
       "      <td>   EOCOPD</td>\n",
       "      <td>     COPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> freeze5a_NWD100048</td>\n",
       "      <td> NWD100048</td>\n",
       "      <td>    broad</td>\n",
       "      <td>    VU_AF</td>\n",
       "      <td>    AFGen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ent_sample_id  sample_id    CENTER     study topmed_project\n",
       "0  freeze5a_NWD100014  NWD100014        uw       JHS            JHS\n",
       "1  freeze5a_NWD100018  NWD100018     broad  COPDGene           COPD\n",
       "2  freeze5a_NWD100027  NWD100027  macrogen  GeneSTAR       GeneSTAR\n",
       "3  freeze5a_NWD100047  NWD100047        uw    EOCOPD           COPD\n",
       "4  freeze5a_NWD100048  NWD100048     broad     VU_AF          AFGen"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model = fiss.fapi.get_entities_tsv(\"topmed-shared\",\"topmed-shared\", \"sample\")\n",
    "data_model_text = pd.read_csv(io.StringIO(data_model.text), sep='\\t')[['entity:sample_id','participant','CENTER','study','topmed_project']]\n",
    "data_model_text.rename(columns = {'entity:sample_id':'ent_sample_id', 'participant':'sample_id'}, inplace = True)\n",
    "data_model_text[['study', 'topmed_project']] = data_model_text[['study', 'topmed_project']].astype(str)\n",
    "data_model_text.info()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlctx = SQLContext(hc.sc)\n",
    "spark_df = sqlctx.createDataFrame(data_model_text)\n",
    "kt = KeyTable.from_dataframe(spark_df,key='sample_id') \n",
    "vds = vds.annotate_samples_table(kt, root='sa')\n",
    "\n",
    "data_model_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'AA_CAC': 1234L,\n",
      " u'AFGen': 2875L,\n",
      " u'Amish': 1030L,\n",
      " u'BAGS': 968L,\n",
      " u'CFS': 923L,\n",
      " u'COPD': 8808L,\n",
      " u'CRA': 1043L,\n",
      " u'FHS': 3660L,\n",
      " u'GOLDN': 904L,\n",
      " u'GenSalt': 1695L,\n",
      " u'GeneSTAR': 1545L,\n",
      " u'HyperGEN_GENOA': 2822L,\n",
      " u'JHS': 3136L,\n",
      " u'MESA': 4178L,\n",
      " u'PGX_Asthma': 1366L,\n",
      " u'SAFS': 1509L,\n",
      " u'SAS': 1208L,\n",
      " u'Sarcoidosis': 608L,\n",
      " u'VTE': 4864L,\n",
      " u'WHI': 10047L,\n",
      " u'nan': 76L}\n"
     ]
    }
   ],
   "source": [
    "pprint(vds.query_samples('samples.map(s => sa.topmed_project).counter()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = vds.variant_qc().cache().sample_qc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struct{\n",
      "     ent_sample_id: String,\n",
      "     CENTER: String,\n",
      "     study: String,\n",
      "     topmed_project: String,\n",
      "     qc: Struct{\n",
      "         callRate: Double,\n",
      "         nCalled: Int,\n",
      "         nNotCalled: Int,\n",
      "         nHomRef: Int,\n",
      "         nHet: Int,\n",
      "         nHomVar: Int,\n",
      "         nSNP: Int,\n",
      "         nInsertion: Int,\n",
      "         nDeletion: Int,\n",
      "         nSingleton: Int,\n",
      "         nTransition: Int,\n",
      "         nTransversion: Int,\n",
      "         dpMean: Double,\n",
      "         dpStDev: Double,\n",
      "         gqMean: Double,\n",
      "         gqStDev: Double,\n",
      "         nNonRef: Int,\n",
      "         rTiTv: Double,\n",
      "         rHetHomVar: Double,\n",
      "         rInsertionDeletion: Double\n",
      "     }\n",
      " }\n"
     ]
    }
   ],
   "source": [
    "pprint(vds.sample_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## actually want to look at proportion per cohort of singletons/doubles/etc\n",
    "\n",
    "# annotate by allele count and frequency for each sample\n",
    "vds = vds.annotate_samples_expr('sa.nDoubles = gs.filter(g => g.isHet() && va.qc.AC == 2).count()')\n",
    "vds = vds.annotate_samples_expr('sa.nTri_to_one = gs.filter(g => g.isHet() && va.qc.AC == 3).count()')\n",
    "vds = vds.annotate_samples_expr('sa.nOne = gs.filter(g => g.isHet() && va.qc.AF < 0.01 && va.qc.AF > 0.001).count()')\n",
    "vds = vds.annotate_samples_expr('sa.nTen = gs.filter(g => g.isHet() && va.qc.AF < 0.1 && va.qc.AF > 0.01).count()')\n",
    "vds = vds.annotate_samples_expr('sa.nTen_above = gs.filter(g => g.isHet() && va.qc.AF > 0.1).count()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(vds.samples_table()\n",
    " .aggregate_by_key(key_expr=['Pop = sa.topmed_project'], agg_expr=['Singletons = sa.map(s => sa.qc.nSingleton).stats().sum',\n",
    "                                                                                          'Doubletons = sa.map(s => sa.nDoubles).stats().sum',\n",
    "                                                                                          'Tripletons_to_01 = sa.map(sa => sa.nTri_to_one).stats().sum',\n",
    "                                                                                          'Zero_1_to_1 = sa.map(sa => sa.nOne).stats().sum',\n",
    "                                                                                          'One_to_10 = sa.map(sa => sa.nTen).stats().sum',\n",
    "                                                                                          'Ten_above = sa.map(sa => sa.nTen_above).stats().sum']).to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running PCA on Freeze 5b Genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do pca\n",
    "pca = vds.pca('sa.pca', k=5, eigenvalues='global.eigen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the differences in families within the studies by principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some colors\n",
    "c = [\"aec7e8\",\"ff7f0e\",\"ffbb78\",\"2ca02c\",\"98df8a\",\"d62728\",\"ff9896\",\"9467bd\",\"c5b0d5\",\"8c564b\",\"c49c94\"]\n",
    "cz = zip(vds.query_samples('samples.map(s => sa.topmed_project).counter()').keys(),c)\n",
    "colors = {t[0]: t[1] for t in cz}\n",
    "# show the pca results\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import Counter\n",
    "from math import log, isnan\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "pca_table = pca.samples_table().to_pandas()\n",
    "plt.scatter(pca_table[\"sa.pca.PC1\"], pca_table[\"sa.pca.PC2\"],\n",
    "            c = pca_table[\"sa.metadata.SuperPopulation\"].map(colors),\n",
    "            alpha = .5)\n",
    "plt.xlim(-0.6, 0.6)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "legend_entries = [mpatches.Patch(color=c, label=pheno) for pheno, c in colors.items()]\n",
    "plt.legend(handles=legend_entries, loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
