{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant annotations in hail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install firecloud\n",
    "from firecloud import fiss\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_row', 10000)\n",
    "import io\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_sets = fiss.fapi.get_entities('topmed-shared','topmed-shared', 'sample_set').json()\n",
    "print 'Sample set name:', samples_sets[0]['name']\n",
    "print 'Sample set fields:', ', '.join(samples_sets[0]['attributes'].keys())\n",
    "vcf_files = samples_sets[0]['attributes']['vcf']['items']\n",
    "print '# of vcf files:', len(vcf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hail import *\n",
    "hc = HailContext(log=\"/topmed.log\")\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import vcf to vds and split any multi allelic sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vds = hc.import_vcf('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/freeze.5b.chr10.phased.pass.minDP0.remDuplicates.vcf.bgz',min_partitions = 1000).split_multi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import wgsa annotations as a key table. This line does the following:\n",
    "    1: import full csv\n",
    "    2: make a _variant_ type field\n",
    "    3: key by the variant\n",
    "    4: remove unneeded fields\n",
    "    5: split the vep annotations into an array for each variant (there can be multiple annotations)\n",
    "    6: expand each variant row to 1 row per vep annotation for ease of filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kt = hc.import_table('freezes_2a_3a_4.snp_indel.annotated.general20170422.subset.gz.chr20.csv',delimiter='\\t').annotate(\"v = chr+':'+pos+':'+ref+':'+alt\").annotate('v = Variant(v)').key_by('v').drop(['pos','alt','chr','ref','wgsa_version']).annotate(\"VEP_ensembl_Consequence = VEP_ensembl_Consequence.split(',')\").explode('VEP_ensembl_Consequence')\n",
    "\n",
    "kt = (hc.import_table('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/annotations/freeze.5.chr10.wgsa.noncoding.vep.tsv',delimiter='\\t')\n",
    "      .annotate(\"chr = 'chr'+CHROM\")\n",
    "      .annotate(\"v = chr+':'+POS+':'+REF+':'+ALT\")\n",
    "      .annotate('v = Variant(v)')\n",
    "      .key_by('v')\n",
    "      .drop(['POS','ALT','chr','REF','CHROM','wgsa_version'])\n",
    "      .annotate(\"VEP_ensembl_Consequence = VEP_ensembl_Consequence.split(',')\")\n",
    "      .explode('VEP_ensembl_Consequence')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'CADD_phred': u'4.946',\n",
      "  u'CADD_raw': u'0.225505',\n",
      "  u'DANN_score': u'0.50821951740435234',\n",
      "  u'Eigen_PC_phred': u'4.16501',\n",
      "  u'Eigen_PC_raw': u'-0.159546417332822',\n",
      "  u'Eigen_coding_or_noncoding': u'n',\n",
      "  u'Eigen_phred': u'1.30879',\n",
      "  u'Eigen_raw': u'-0.303227552104844',\n",
      "  u'GenoCanyon_score': u'2.78746919547125E-4',\n",
      "  u'RegulomeDB_score': u'6',\n",
      "  u'VEP_ensembl_Consequence': u'downstream_gene_variant',\n",
      "  u'VEP_ensembl_Gene_ID': u'ENSG00000260370',\n",
      "  u'VEP_ensembl_Transcript_ID': u'ENST00000566940',\n",
      "  u'fathmm_MKL_non_coding_pred': u'.',\n",
      "  u'funseq2_noncoding_score': u'0',\n",
      "  u'funseq_noncoding_score': u'.',\n",
      "  u'integrated_fitCons_score': u'0.061011',\n",
      "  u'v': Variant(contig=chr10, start=10023, ref=C, alts=[AltAllele(ref=C, alt=A)])}]\n"
     ]
    }
   ],
   "source": [
    "pprint(kt.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated vds with key table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds = vds.annotate_variants_table(kt, root='va.wgsa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load expression data -> gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "islet_trans = KeyTable.import_bed(\"gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/annotations/t2dreamdb_rnaseq_avgFPKM_greater2_v2.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'interval': Interval(start=Locus(contig=chr1, position=203795655), end=Locus(contig=chr1, position=203855000)),\n",
      "  u'target': u'ENSG00000058673'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(islet_trans.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "islet_trans_pad = KeyTable.import_bed(\"gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/annotations/t2dreamdb_rnaseq_avgFPKM_greater2_padding_v2.bed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the islet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "islet_states = KeyTable.import_bed('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/annotations/Islets.chromatinStates.hg38.v2.bed').filter('target == \"10_Active_enhancer_2\" || target == \"9_Active_enhancer_1\"')                           \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load islet tfbs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "islet_tfbs_file = 'gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/annotations/all_tfbs_chr10.enhancer.hg38.bed'\n",
    "islet_tfbs = KeyTable.import_bed(islet_tfbs_file)\n",
    "# islet_tfbs = hc.import_table(islet_tfbs_file,delimiter=',').annotate(\"i = V1+':'+V2+'-'+V3\" ).annotate('i = Interval(i)').key_by('i')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find variants that fall within expressed genes or islet states or ptv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds = (vds.variant_qc()\n",
    "       .cache()\n",
    "       .filter_variants_expr('va.qc.AF < 0.01')\n",
    "       .annotate_variants_table(islet_trans_pad,root='va.gene')\n",
    "       .annotate_variants_table(islet_states,root='va.chr_state')\n",
    "       .annotate_variants_table(islet_tfbs,root='va.tfbs')\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vds = vds.filter_variants_expr('va.chr_state == \"10_Active_enhancer_2\" || va.chr_state == \"9_Active_enhancer_1\" || isDefined(va.tfbs) ||  va.wgsa.VEP_ensembl_Consequence == \"splice_acceptor_variant\"  || va.wgsa.VEP_ensembl_Consequence == \"splice_donor_variant\" || va.wgsa.VEP_ensembl_Consequence== \"splice_region_variant\" || va.wgsa.VEP_ensembl_Consequence == \"stop_gained\" || va.wgsa.VEP_ensembl_Consequence == \"stop_lost\" || va.wgsa.VEP_ensembl_Consequence == \"start_gained\" || va.wgsa.VEP_ensembl_Consequence == \"start_lost\" || va.wgsa.VEP_ensembl_Consequence == \"frameshift_variant\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds_all_in_gene_pad = vds.filter_variants_table(islet_trans_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds_all_in_gene = vds.filter_variants_table(islet_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vds_ptv = vds_all_in_gene.filter_variants_expr('va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"splice_acceptor_variant\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"splice_donor_variant\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"splice_region_variant\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"stop_gained\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"stop_lost\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"start_gained\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"start_lost\")) || va.wgsa.VEP_ensembl_Consequence.forall(tc => tc.toSet.contains(\"frameshift_variant\"))')\n",
    "\n",
    "vds_tfbs = vds_all_in_gene_pad.filter_variants_table(islet_tfbs)\n",
    "vds_states = vds_all_in_gene_pad.filter_variants_table(islet_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54035L, 10225L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vds_ptv = vds_all_in_gene.filter_variants_expr('va.wgsa.VEP_ensembl_Consequence == \"splice_acceptor_variant\"  || va.wgsa.VEP_ensembl_Consequence == \"splice_donor_variant\" || va.wgsa.VEP_ensembl_Consequence== \"splice_region_variant\" || va.wgsa.VEP_ensembl_Consequence == \"stop_gained\" || va.wgsa.VEP_ensembl_Consequence == \"stop_lost\" || va.wgsa.VEP_ensembl_Consequence == \"start_gained\" || va.wgsa.VEP_ensembl_Consequence == \"start_lost\" || va.wgsa.VEP_ensembl_Consequence == \"frameshift_variant\"')\n",
    "vds_ptv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vds_tfbs.write('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/testing-5b-chr10/chr10_tfbs.vds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds_states.write('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/testing-5b-chr10/chr10_states.vds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vds_ptv.write('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/testing-5b-chr10/chr10_ptv.vds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "union_vds = hc.read(['gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/testing-5b-chr10/chr10_tfbs.vds', 'gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/testing-5b-chr10/chr10_states.vds','gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/testing-5b-chr10/chr10_ptv.vds'])\n",
    "union_vds.variant_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(union_vds\n",
    " .export_variants('gs://dataproc-0a502eb9-92d4-4031-a99d-7b98ab92717b-us/testing-5b-chr10/freeze5b_chr10_rarevar_v1.tsv', 'group_id = va.gene, chromosome = v.locus.contig, variant_id = va.rsid, position=v.locus.position, ref = v.ref, alt=v.alt, VEP_ensembl_Consequence = va.wgsa.VEP_ensembl_Consequence, chromatin_state = va.chr_state, tfbs = va.tfbs, allele_count = va.qc.AC, CADD_phred = va.wgsa.CADD_phred, DANN_score = va.wgsa.DANN_score, Eigen_PC_phred = va.wgsa.Eigen_PC_phred, Eigen_phred=va.wgsa.Eigen_phred, Eigen_coding_or_noncoding = va.wgsa.Eigen_coding_or_noncoding, GenoCanyon_score = va.wgsa.GenoCanyon_score, RegulomeDB_score = va.wgsa.RegulomeDB_score, fathmm_MKL_non_coding_pred = va.wgsa.fathmm_MKL_non_coding_pred, funseq2_noncoding_score = va.wgsa.funseq2_noncoding_score, funseq_noncoding_score = va.wgsa.funseq_noncoding_score, integrated_fitCons_score = va.wgsa.integrated_fitCons_score')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vds.query_variants('variants.take(5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# ! pip install firecloud\n",
    "# from firecloud import fiss\n",
    "# import pandas as pd\n",
    "# import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vds_subset = vds_subset.variant_qc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_model = fiss.fapi.get_entities_tsv(\"topmed-shared\",\"topmed-shared\", \"sample\")\n",
    "# data_model_text = pd.read_csv(io.StringIO(data_model.text), sep='\\t')[['entity:sample_id','participant','CENTER','study','topmed_project']]\n",
    "# data_model_text.rename(columns = {'entity:sample_id':'ent_sample_id', 'participant':'sample_id'}, inplace = True)\n",
    "# data_model_text[['study', 'topmed_project']] = data_model_text[['study', 'topmed_project']].astype(str)\n",
    "# from pyspark.sql import SQLContext\n",
    "# sqlctx = SQLContext(hc.sc)\n",
    "# spark_df = sqlctx.createDataFrame(data_model_text)\n",
    "# kt = KeyTable.from_dataframe(spark_df,key='sample_id')\n",
    "# vds = vds_subset.annotate_samples_table(kt, root='sa').sample_qc()\n",
    "# vds = vds.annotate_samples_expr('sa.nDoubles = gs.filter(g => g.isHet() && va.qc.AC == 2).count()')\n",
    "# vds = vds.annotate_samples_expr('sa.nTri_to_one = gs.filter(g => g.isHet() && va.qc.AC == 3).count()')\n",
    "# vds = vds.annotate_samples_expr('sa.nOne = gs.filter(g => g.isHet() && va.qc.AF < 0.01 && va.qc.AF > 0.001).count()')\n",
    "# vds = vds.annotate_samples_expr('sa.nTen = gs.filter(g => g.isHet() && va.qc.AF < 0.1 && va.qc.AF > 0.01).count()')\n",
    "# vds = vds.annotate_samples_expr('sa.nTen_above = gs.filter(g => g.isHet() && va.qc.AF > 0.1).count()')\n",
    "# vds.samples_table().aggregate_by_key(key_expr=['Pop = sa.topmed_project'], agg_expr=['Singletons = sa.map(s => sa.qc.nSingleton).stats().sum',\n",
    "#                                                                                           'Doubletons = sa.map(s => sa.nDoubles).stats().sum',\n",
    "#                                                                                           'Tripletons_to_01 = sa.map(sa => sa.nTri_to_one).stats().sum',\n",
    "#                                                                                           'Zero_1_to_1 = sa.map(sa => sa.nOne).stats().sum']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vds.samples_table().aggregate_by_key(key_expr=['Pop = sa.topmed_project'], agg_expr=['Single = sa.map(s => sa.qc.nSingleton).stats()']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}